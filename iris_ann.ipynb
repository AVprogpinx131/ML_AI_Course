{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_mount_drive():\n",
    "    \"\"\"Mount Google Drive. For local usage only.\"\"\"\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        import os\n",
    "        os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"Google Colab module not found. Skipping Google Drive mount.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"Read the iris dataset with the correct column names.\"\"\"\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    data.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_to_numerical(data):\n",
    "    \"\"\"Encode the labels to numerical values. eg. iris_color to 0.\"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['species'] = label_encoder.fit_transform(data['species'])\n",
    "    return data, label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82274a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_as_one_hot(y, num_classes=3):\n",
    "    \"\"\"Encodes labels to one-hot format. Use keras.utils to_categorical function for this.\"\"\"\n",
    "    from keras.utils import to_categorical\n",
    "    return to_categorical(y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbda934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features_and_labels(data):\n",
    "    \"\"\"Split the dataset into features and labels.\"\"\"\n",
    "    features = data.drop('species', axis=1).values\n",
    "    labels = data['species'].values\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb91a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_test_and_train(X, y):\n",
    "    \"\"\"Split the dataset into two for testing and validation. Choose the proper split.\"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create a model with different layers.\"\"\"\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b81c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    \"\"\"Use the model.compile function to compile the model with a loss function, optimizer and metrics.\"\"\"\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe48475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, X_test, y_train, y_test, epochs=150):\n",
    "    \"\"\"Train the the model using training and testing datasets.\"\"\"\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=5, validation_data=(X_test, y_test), verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0607d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model using testing dataset. Use the built-in model.evaluate function to find and return the accuracy.\"\"\"\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_using_predictions(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model using testing dataset. Use the built-in model.predict function and compare the predictions against the actual values. Return the accuracy value.\"\"\"\n",
    "    import numpy as np\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Convert one-hot encoded y_test to class indices\n",
    "    actual_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Now both arrays are shape (30,)\n",
    "    accuracy = np.mean(predicted_classes == actual_classes)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96327d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    running_locally = try_to_mount_drive()\n",
    "\n",
    "    # This is necessary for testing purposes.\n",
    "    if not running_locally:\n",
    "        return\n",
    "    \n",
    "    # Proceed with logic\n",
    "    data = read_data('iris.data')\n",
    "    encode_labels_to_numerical(data)\n",
    "    X, y = separate_features_and_labels(data)\n",
    "\n",
    "    # Encode labels to one-hot vectors\n",
    "    y = encode_labels_as_one_hot(y, num_classes=3)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = split_data_to_test_and_train(X, y)\n",
    "\n",
    "    # Model creation, compilation, and training\n",
    "    model = create_model()\n",
    "    compile_model(model)\n",
    "    history = train_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Model evaluation\n",
    "    accuracy = evaluate_model(model, X_test, y_test)\n",
    "    print('Accuracy: %.2f' % (accuracy * 100))\n",
    "\n",
    "    prediction_accuracy = evaluate_using_predictions(model, X_test, y_test)\n",
    "    print(f'Total accuracy: {prediction_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Print model configuration\n",
    "    config = model.get_config()\n",
    "    print(config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13030947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
